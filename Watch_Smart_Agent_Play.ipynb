{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env = UnityEnvironment(file_name=\"Reacher-2.app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ddpg_agent import Agent\n",
    "from model import Actor, Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load saved network\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "actor =  Actor(state_size, action_size, False, 0).to(device)\n",
    "actor.load_state_dict(torch.load('best_checkpoint_actor.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "critic = Critic(state_size, action_size, False, 0).to(device)\n",
    "critic.load_state_dict(torch.load('best_checkpoint_critic.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyper = {'BUFFER_SIZE' : int(1e6)  # replay buffer size\n",
    ",'BATCH_SIZE' : 256        # minibatch size\n",
    ",'GAMMA' : 0.99            # discount factor\n",
    ",'TAU' : 1e-3              # for soft update of target parameters\n",
    ",'LR_ACTOR' : 1e-3         # learning rate of the actor\n",
    ",'LR_CRITIC' : 1e-3        # learning rate of the critic\n",
    ",'WEIGHT_DECAY' : 0        # L2 weight decay\n",
    ",'UPDATE_EVERY' : 20       # timesteps between updates\n",
    ",'NUM_UPDATES' : 10        # num of update passes when updating\n",
    ",'EPSILON' : 1.0           # epsilon for the noise process added to the actions\n",
    ",'EPSILON_DECAY' : 0       # decay for epsilon above\n",
    ",'NOISE_SIGMA' : 0.01      # sigma for Ornstein-Uhlenbeck noise\n",
    ",'USE_BATCH_NORM' : False }\n",
    "\n",
    "smart_agent = Agent(state_size=state_size, action_size=action_size, random_seed=0, hyper=hyper, actor=actor, critic=critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smart_agent.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to play game\n",
    "def playGame(agent, n_episodes=100, max_t=1000, eps_start=.01, eps_end=0.001, eps_decay=0.995, print_every = 50):\n",
    "    eps = eps_start \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=False)[brain_name]\n",
    "        state = env_info.vector_observations\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            \n",
    "            next_state = env_info.vector_observations   # get the next state\n",
    "            reward = env_info.rewards                  # get the reward\n",
    "            done = env_info.local_done    \n",
    "    \n",
    "            # next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done, t)\n",
    "            state = next_state\n",
    "            score += np.mean(reward)\n",
    "            \n",
    "            if np.any(done):\n",
    "                break \n",
    "        if i_episode % print_every == 0:\n",
    "            print(\"Score at episode %s : %s\" % (i_episode, score))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "playGame(smart_agent, n_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:drlnd]",
   "language": "python",
   "name": "conda-env-drlnd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
